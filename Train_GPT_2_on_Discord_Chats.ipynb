{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudo-logic/Train_GPT_2_on_Discord_Chats/blob/main/Train_GPT_2_on_Discord_Chats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Training a GPT-2 Text-Generating Model on Discord Chats\n",
        "\n",
        "by [Ayush Mishra](https://github.com/sudo-logic)\n",
        "\n",
        "\n",
        "Retraining a Text Generation Model on Discord Chats using `gpt-2-simple` that wraps existing model fine-tuning and generation scripts for OpenAI's GPT-2.\n",
        "\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V39etOh1fQAg"
      },
      "source": [
        "##GPU\n",
        "\n",
        "GPU Hardware Acceleration is needed to make the model training magnitudes faster. \n",
        "\n",
        "Make sure you have selected GPU as your Hardware Accelerator in Runtime Settings.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jFNEcEJ4EPWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97217596-401a-4fc5-cdbb-1152419252bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 12 19:18:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    65W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDHKgMymcGZJ"
      },
      "source": [
        "##Install and import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rYaApsdd4spo"
      },
      "outputs": [],
      "source": [
        "!pip install -q gpt-2-simple \n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from IPython.display import clear_output "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lstKFOKcP-D"
      },
      "source": [
        "##Addressing Variables\n",
        "The number of messages and Channel ID to be scraped along with the User/Bot Token for authorization need to be specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eXQ4sqAM9jaD"
      },
      "outputs": [],
      "source": [
        "auth_token = '' #Looks like 'MzgxNDUxMjcxNTg2MTg1MjI3.YWwWOg.CI7-cRZCpGjB8pN4whQxOaOZ4S5'\n",
        "channel_id = 750068339375603725 #Looks like 750068339375603725\n",
        "message_count = 30000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhdBgoipdEP8"
      },
      "source": [
        "##Gathering the Training Data\n",
        "Scrape the Discord chats using raw GET requests and save them in a data.txt file after proper formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e257z0pU4_Mv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41ff91f-5c8d-49b0-a27f-be837886fabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%\n",
            "Scraped Discord Messages Successfully\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "869560"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "headers = {'authorization': auth_token,}\n",
        "params = {\n",
        "  'limit': '100',\n",
        "}\n",
        "\n",
        "params['before'] = None\n",
        "\n",
        "data = []\n",
        "chat_data = []\n",
        "for i in range(int(message_count/100)):\n",
        "  messages = requests.get(f'https://discord.com/api/v9/channels/{channel_id}/messages', headers=headers, params=params).json()\n",
        "  # print(messages)\n",
        "  for message in messages:\n",
        "    data.append(message)\n",
        "    # print(message)\n",
        "    chat_data.append(f\"{message['author']['username']}: {message['content']}\")\n",
        "  clear_output()\n",
        "  print(f'{int((len(chat_data)/message_count)*100)}%')\n",
        "\n",
        "  params['before'] = messages[-1]['id']\n",
        "\n",
        "print(\"Scraped Discord Messages Successfully\")\n",
        "\n",
        "content = '\\n'.join(chat_data)\n",
        "open('data.txt','w').write(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypk0hxRZdz5g"
      },
      "source": [
        "##Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "---\n",
        "\n",
        "I have used the \"small\" model simply because it trains quicker. Larger models will give out more accurate outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-N6UsR043Iq",
        "outputId": "0cc08443-9862-4fbd-c608-3f6413a816b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 265Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.34Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 429Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:10, 48.2Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 361Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 8.44Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 7.25Mit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om4bqm5ckee8"
      },
      "source": [
        "## Finetuning\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p02qIyQk45_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cfb410-4e2e-4d8b-b4f6-736d7b1a5ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 376163 tokens\n",
            "Training...\n",
            "[1 | 8.20] loss=3.01 avg=3.01\n",
            "[2 | 12.32] loss=3.04 avg=3.02\n",
            "[3 | 16.45] loss=2.67 avg=2.90\n",
            "[4 | 20.58] loss=2.67 avg=2.84\n",
            "[5 | 24.71] loss=2.79 avg=2.83\n",
            "[6 | 28.85] loss=3.28 avg=2.91\n",
            "[7 | 33.00] loss=2.96 avg=2.92\n",
            "[8 | 37.15] loss=2.81 avg=2.90\n",
            "[9 | 41.30] loss=2.75 avg=2.89\n",
            "[10 | 45.47] loss=2.84 avg=2.88\n",
            "[11 | 49.63] loss=2.67 avg=2.86\n",
            "[12 | 53.81] loss=2.97 avg=2.87\n",
            "[13 | 57.99] loss=2.81 avg=2.87\n",
            "[14 | 62.18] loss=2.95 avg=2.87\n",
            "[15 | 66.37] loss=2.96 avg=2.88\n",
            "[16 | 70.56] loss=2.78 avg=2.87\n",
            "[17 | 74.76] loss=2.86 avg=2.87\n",
            "[18 | 78.95] loss=2.67 avg=2.86\n",
            "[19 | 83.16] loss=2.69 avg=2.85\n",
            "[20 | 87.37] loss=2.67 avg=2.84\n",
            "======== SAMPLE 1 ========\n",
            "ip.mp4\n",
            "MISSISSISSISSIP.mp4\n",
            "MISSION: Hi!\n",
            "mihdia: lol\n",
            "mihdia: so ur gonna say it ur name to the people\n",
            "mihdia: i am\n",
            "fizz: I wanna say this :D\n",
            "mihdia: you wanna say the name im gonna add at the bottom\n",
            "mihdia: yeah\n",
            "mihdia: ooo\n",
            "fizz: D:sadly\n",
            "xxxy: <:adm1> <a:xpeepoMarsLover:94825586775694844>\n",
            "fizz: Hi\n",
            "oPooDani: Hi\n",
            "Fizz: <a:Fizz:857144848278079079>\n",
            "xox.: Hi\n",
            "mihdia: i dont hate im good guy but ur name\n",
            "xox.: I hate my name\n",
            "fizz: Omg\n",
            "PooDani: \n",
            "xox.: Y\n",
            "Omikazu: üíÄ üíÄ üíÄ üëå üíÄ üëå ‚ù§Ô∏è üêô üíÄ üì± ü•ô üî• üì• üì± üì∞ üëç üëç üëçüëç üëç üëçüëç üëçüëç üëçüëçüëç üëçüëçüëçüëç ‚òïÔ∏è\n",
            "mihdia: omg\n",
            "xox.: I hate my name.\n",
            "PooDani: üòÄ\n",
            "MISSISSISSISSIP.mp4\n",
            "fizz: Hi\n",
            "xox.: Hh\n",
            "joshito: Oooooo\n",
            "xox.: I'm a fanboy\n",
            "mihdia: why u saying my name\n",
            "PooDani: üíÄ\n",
            "Omikazu: Im a kid\n",
            "Omikazu: I dont even know you have a name\n",
            "oPooDani: I'm not a kid\n",
            "xox.: How old u were at 12\n",
            "xox.: I was 13 in high school but i still have no sense of sense of sense of sense of sense of sense of sense of sense of sense for that whole 12th üì∂üè•\n",
            "xox.: Lol my friend is dead\n",
            "Danao: Im sure\n",
            "Danao: Im sure it is hard to see you\n",
            "xox.: I dont make too much money bro\n",
            "X.: Ape is a girl\n",
            "krok: Im a 16 year old boy so it takes me about 2hrs per year or 12 per year\n",
            "xox.: The reason I make $10 a day today is because my mom is a c.w.a\n",
            "xox.: My mom is pretty\n",
            "xox.: Im talking to a 17 year old girl bro\n",
            "xox.: I got my dad's phone number and she is 19\n",
            "xox.: Who are you\n",
            "X.: A c.w.a\n",
            "Dale: Yessss\n",
            "xox.: I want to eat a little bit of pizza\n",
            "Dale: Aww\n",
            "OoBoom: <:frope:8980808854114089>\n",
            "OoBoom: And that is the server name\n",
            "xox.: Dont know that\n",
            "xox.: My mother is a 16 year old boy and I still have no\n",
            "X.: Oh no i dont\n",
            "Okami: <@61784342548894568:682480482866>\n",
            "Okami: Im not 17 years old.\n",
            "Danao: Lol\n",
            "Danihos: I am very young.\n",
            "Okami: Yes I am.\n",
            "mihdia: I am 17 üíÄ\n",
            "danihos: üíÄ üîß\n",
            "kromah: What?\n",
            "Danihos: <a:xpeepoPoke:87319031448138526>\n",
            "Danihos: It takes a lot to become a c.w.a bro\n",
            "Danihos: It takes years for everyone to find out what am I but my mom is very nice to him and he is very nice to me too!\n",
            "Okami: Thats why I had that nickname\n",
            "Okami: I made a small fortune so as a 13 year old girl I am quite a lot better than my mother is.\n",
            "Okami: This is my dad. He is a nice guy as well and is loving to me. <:xpeepoKazoo:65265047012539061>\n",
            "Oksana: Lush\n",
            "Danihos: I hate saying this: <a:oKromah:82325489825476972>\n",
            "Eros: Im not a 13 year old bro im a 20 year old kid\n",
            "xx\n",
            "\n",
            "[21 | 111.48] loss=2.51 avg=2.82\n",
            "[22 | 115.68] loss=2.70 avg=2.82\n",
            "[23 | 119.89] loss=2.42 avg=2.80\n",
            "[24 | 124.10] loss=2.39 avg=2.78\n",
            "[25 | 128.31] loss=2.60 avg=2.77\n",
            "[26 | 132.51] loss=2.44 avg=2.76\n",
            "[27 | 136.72] loss=2.85 avg=2.76\n",
            "[28 | 140.92] loss=2.62 avg=2.75\n",
            "[29 | 145.11] loss=2.61 avg=2.75\n",
            "[30 | 149.32] loss=2.38 avg=2.73\n",
            "[31 | 153.52] loss=2.72 avg=2.73\n",
            "[32 | 157.71] loss=2.51 avg=2.73\n",
            "[33 | 161.92] loss=2.45 avg=2.72\n",
            "[34 | 166.12] loss=2.42 avg=2.71\n",
            "[35 | 170.32] loss=2.70 avg=2.71\n",
            "[36 | 174.52] loss=2.38 avg=2.69\n",
            "[37 | 178.73] loss=2.68 avg=2.69\n",
            "[38 | 182.93] loss=2.28 avg=2.68\n",
            "[39 | 187.14] loss=2.45 avg=2.67\n",
            "[40 | 191.35] loss=2.40 avg=2.67\n",
            "======== SAMPLE 1 ========\n",
            "P1DtU1Xa7Qs\n",
            "Dino: <:shrug:75449717009620542634>\n",
            "Slat: <:peepoBlanket:7544997222575649988>\n",
            "simp to Shark: c.m 12\n",
            "Dino: c.shrug:505933121740594464>\n",
            "DarkStar: lmfao\n",
            "Zer.: Wtf\n",
            "Dino: \n",
            "Slat: Lmfaoo\n",
            "DarkStar: c.m 13\n",
            "simp to Shark: <a:hmm:8641075002209880>\n",
            "Dino: I am not\n",
            "simp to Shark: damn\n",
            "DarkStar: lmfaao\n",
            "Zer.: https://tenor.com/view/simp-t-gosh-you-hated-em-shrug-shrug-yoda-mahta-kare-banshee-gif-16256988\n",
            "DarkStar: <:haha:962416125575842615>\n",
            "simp to Shark: yaa\n",
            "Dino: c.m13\n",
            "Dino: ok\n",
            "Simp to Shark: damn\n",
            "Dino: ok you get banned\n",
            "Dino: c.m 13\n",
            "simp to Shark: wtf\n",
            "simp to Shark: damn\n",
            "JDW Economy: \n",
            "Treacherous Username: c.m13\n",
            "simp to Shark: simp\n",
            "Dino: oh no no\n",
            "simp to Shark: c.m13\n",
            "JDW Economy: \n",
            "Dino: ok\n",
            "simp to Shark: p.s. c.usm.dams\n",
            "Dino: c.m12\n",
            "JDW Economy: \n",
            "simp to Shark: p.s.dams\n",
            "JDW Economy: \n",
            "simp to Shark: c.m 13\n",
            "Dino: i hate c.us\n",
            "DarkStar: c.m13\n",
            "simp to Shark: c.m13\n",
            "simp to Shark: üòå\n",
            "simp to Shark: c.m11\n",
            "Dino: c.m15\n",
            "DarkStar: lmao\n",
            "simp to Shark: üòé\n",
            "DarkStar: üòé\n",
            "Dino: I hate c.p.\n",
            "Dino: üò•\n",
            "Diyvizio: üò™\n",
            "JDW Economy: \n",
            "Diyvizio: Oh my\n",
            "Diyvizio: üò≥\n",
            "simp to Shark: https://tenor.com/view/simp-paul-carl-saul-cry-pepe-diyvizio-gif-234075\n",
            "JDW Economy: \n",
            "Diyvizio: <:peepoSlut:83418577558249636>\n",
            "simp to Shark: yes\n",
            "Diyvizio: I dont even want to see the video anymore?\n",
            "Diyvizio: Oh it's so sad\n",
            "DarkStar: c.m14\n",
            "simp to Shark: it's just a meme\n",
            "simp to Shark: <a:DangWTFD:893234190841654>\n",
            "Diyvizio: <:ang:792469646944841358>\n",
            "diyvizio: c.s.my grandma\n",
            "Diyvizio: üòõ\n",
            "Diyvizio: üíÄ\n",
            "Diyvizio: üò±\n",
            "simp to Shark: damn\n",
            "DarkStar: <\n",
            "simp to Shark: damn\n",
            "simp to Shark: <:coughpuss:75524071548881854>\n",
            "simp to Shark: c.m12, c.m13\n",
            "simp to Shark: hm\n",
            "Diyvizio: I don't go around talking about moe\n",
            "Diyvizio: She is a friend of mine that has been married to me for 5 years\n",
            "simp to Shark: üò§\n",
            "simp to Shark: c.m 12\n",
            "simp to Shark: o.o\n",
            "Diyvizio: üòè\n",
            "simp to Shark: c.m12\n",
            "DarkStar: üò≥\n",
            "simp to Shark: üòÖ\n",
            "simp to Shark: üò¶\n",
            "simp to Shark: lmao\n",
            "simp to Shark: üòê\n",
            "Dioy: <@!8480772698572426> I love you guys\n",
            "DarkStar: üí°üí∂üí∂üí∂‚Äèüë•üìú\n",
            "JDW Economy: \n",
            "Dioy: wtf\n",
            "simp to Shark: üòè\n",
            "Dioy: what\n",
            "Dioy: what\n",
            "simp to Shark: üíÄ\n",
            "simp to Shark: s.n\n",
            "simp to\n",
            "\n",
            "[41 | 214.45] loss=2.70 avg=2.67\n",
            "[42 | 218.66] loss=2.55 avg=2.66\n",
            "[43 | 222.87] loss=2.26 avg=2.65\n",
            "[44 | 227.08] loss=2.37 avg=2.64\n",
            "[45 | 231.28] loss=2.03 avg=2.63\n",
            "[46 | 235.48] loss=2.44 avg=2.62\n",
            "[47 | 239.68] loss=2.40 avg=2.62\n",
            "[48 | 243.89] loss=2.39 avg=2.61\n",
            "[49 | 248.10] loss=2.56 avg=2.61\n",
            "[50 | 252.30] loss=2.24 avg=2.60\n",
            "Saving checkpoint/run1/model-50\n",
            "[51 | 259.45] loss=2.57 avg=2.60\n",
            "[52 | 263.66] loss=2.33 avg=2.59\n",
            "[53 | 267.87] loss=2.35 avg=2.59\n",
            "[54 | 272.07] loss=2.36 avg=2.58\n",
            "[55 | 276.34] loss=2.29 avg=2.57\n",
            "[56 | 280.58] loss=2.14 avg=2.56\n",
            "[57 | 284.83] loss=2.34 avg=2.56\n",
            "[58 | 289.05] loss=2.41 avg=2.56\n",
            "[59 | 293.24] loss=2.16 avg=2.55\n",
            "[60 | 297.40] loss=2.47 avg=2.55\n",
            "======== SAMPLE 1 ========\n",
            "ES1: <:peepoSmile:871927105430267940>\n",
            "Dystopia: <@8906334480486020> <:Bruh:74467013625352789>\n",
            "Dystopia: <@724629103988373860>\n",
            "simp to Shark: <:peepoPity:883788161536295740>\n",
            "Dinky: <:peepoPity:883788161536295740>\n",
            "simp to Shark: what's up bud\n",
            "PepperedOxy: <:shrug:8393901797469282220>\n",
            "Jayy: <:peepoWhew:852705402766364028>\n",
            "simp to Shark: c.m 11\n",
            "JDW Economy: \n",
            "JDW Economy: \n",
            "simp to Shark: c.m 12\n",
            "JDW Economy: \n",
            "simp to Shark: <:shrug:8393901797469282220>\n",
            "simp to Shark: c.m 2\n",
            "simp to Shark: nice\n",
            "simp to Shark: nice\n",
            "Jayy: <:peepoBruh:871927105430267940>\n",
            "PepperedOxy: \n",
            "Dyno: <:peepoSpewer:842180541528890620>\n",
            "Dystopia: <@971236109700695580> is there a difference between normal spelling of \"shiro\" and \"shiro\" and c.m 13?\n",
            "simp to Shark: <:peepoBlame:75536738140773584>\n",
            "PepperedOxy: c.m 13\n",
            "Jayy: <:peepoBlame:75536738140773584>\n",
            "simp to Shark: ü§£\n",
            "PepperedOxy: oh ok\n",
            "Jayy: <:peepoGrind:890615572597291833>\n",
            "PepperedOxy: but\n",
            "PepperedOxy: and he can do no good\n",
            "simp to Shark: c.m 4\n",
            "Sare: ü§£\n",
            "PepperedOxy: and he can do no good\n",
            "Jayy: <:peepoGrind:890615572597291833>\n",
            "PepperedOxy: lol\n",
            "PepperedOxy: <:peepoGrind:890615572597291833>\n",
            "PepperedOxy: i hope it worked in my test i wish it\n",
            "Jayy: I love you\n",
            "MEE6: <@84738332219056628> Has advanced to **level 14**! <a:xpeepoJetBubbles:762409048220893234>\n",
            "PepperedOxy: lol\n",
            "PepperedOxy: c.us c.us\n",
            "PepperedOxy: im not doing anything\n",
            "PepperedOxy: c.us\n",
            "Jayy: <a:sadly:768414572810252537>\n",
            "PepperedOxy: c.us\n",
            "PepperedOxy: <@!907927804768282072> im doing shit, but i dont want to listen to u guys chat\n",
            "simp to Shark: https://tenor.com/view/rooster-reboot-gif-11740185\n",
            "PepperedOxy: c.us\n",
            "PepperedOxy: i'm gonna use an uk account\n",
            "PepperedOxy: you are\n",
            "PepperedOxy: i like ur memes\n",
            "pepperedOxy: ur best friend\n",
            "Mehh o Chaz: bro\n",
            "Mehh o Chaz: hi\n",
            "Jayy: <@!836733221905662815>\n",
            "Mehh o Chaz: u did it ü§£\n",
            "PepperedOxy: i'm gonna use an uk account\n",
            "PepperedOxy: ok\n",
            "Mehh o Chaz: it's <:peepoPronies:809624017906336954>\n",
            "Mehh o Chaz: <:peepoBlanket:9230422193318674456>\n",
            "Dinky: <a:MMA:745634338428471601>\n",
            "PepperedOxy: <:peepoGrind:890615572597291833>\n",
            "Mehh o Chaz: üòí\n",
            "Jayy: <:peepoS:8832140981366756736>\n",
            "PepperedOxy: https://tenor.com/view/me-ro\n",
            "\n",
            "[61 | 320.49] loss=2.40 avg=2.54\n",
            "[62 | 324.67] loss=2.26 avg=2.54\n",
            "[63 | 328.85] loss=2.46 avg=2.53\n",
            "[64 | 333.07] loss=2.50 avg=2.53\n",
            "[65 | 337.32] loss=2.24 avg=2.53\n",
            "[66 | 341.55] loss=2.53 avg=2.53\n",
            "[67 | 345.78] loss=2.32 avg=2.52\n",
            "[68 | 349.96] loss=2.51 avg=2.52\n",
            "[69 | 354.12] loss=2.03 avg=2.51\n",
            "[70 | 358.29] loss=2.25 avg=2.51\n",
            "[71 | 362.46] loss=2.21 avg=2.50\n",
            "[72 | 366.62] loss=2.27 avg=2.50\n",
            "[73 | 370.79] loss=2.29 avg=2.49\n",
            "[74 | 374.97] loss=2.22 avg=2.49\n",
            "[75 | 379.15] loss=2.56 avg=2.49\n",
            "[76 | 383.35] loss=2.42 avg=2.49\n",
            "[77 | 387.54] loss=2.27 avg=2.48\n",
            "[78 | 391.74] loss=2.36 avg=2.48\n",
            "[79 | 395.93] loss=2.22 avg=2.48\n",
            "[80 | 400.17] loss=2.32 avg=2.47\n",
            "======== SAMPLE 1 ========\n",
            " banned to use Google's API for them?\n",
            "JDW Economy: \n",
            "simp for Shark: https://tenor.com/view/google-mod-gif-18191938\n",
            "Mehh o Chaz: y'know it\n",
            "Zoruo: no\n",
            "Mehh o Chaz:  I agree with your words\n",
            "JDW Economy: \n",
            "ropeharry: I think a lot of its servers are fake\n",
            "JDW Economy: \n",
            "yung u can only sleep in bed when it's really hot.\n",
            "JDW Economy: \n",
            "simp for Shark: Im sorry to hear that but in reality I'm probably more a fan of watching the US version of this game <:th_scoffet:891825695720385884>\n",
            "Sare: <a:sad:553470774092142856>\n",
            "simp for Shark: I kinda want to watch this\n",
            "safa's demise: i don't care how much money I put in\n",
            "JDW Economy: \n",
            "ropeharry: I can not see anyone's demise\n",
            "JDW Economy: \n",
            "safa's demise: oh\n",
            "Mehh o Chaz: hey\n",
            "jungles: damn\n",
            "JDW Economy: \n",
            "ropeharry: Oh yeah\n",
            "safa's demise: I saw that on my phone\n",
            "safa's demise: i love you\n",
            "Mehh o Chaz: <@!820528307930742418>\n",
            "safa's demise: it means so much lol\n",
            "safa's demise: not\n",
            "JDW Economy: \n",
            "safa's demise: so close, i hope to go to therapy\n",
            "ropeharry: I'm glad its been a while\n",
            "ropeharry: And you can be a good teacher\n",
            "yung you can be a nice teacher\n",
            "JDW Economy: \n",
            "safa's demise: aint i gay\n",
            "safa's demise: <a:cry:73217017558343860>\n",
            "safa's demise: cuz hes a boy\n",
            "ropeharry: Idc why I cant ask\n",
            "safa's demise: so\n",
            "JDW Economy: \n",
            "DARKTHIRTY: https://tenor.com/view/just-so-shame-what-i-wondered-how-wrong-they-think-about-you-so-shame-gif-12202599\n",
            "JDW Economy: \n",
            "Sare: <:DARKTHIRTY:998905399049383732>‚Äç\n",
            "ropeharry: Yes\n",
            "ropeharry: <@!844038669538690592>\n",
            "Jungles: <:peepoPeepoBubbles:772409048220893234> <:cry_cram:91076257789859761237>\n",
            "Sare: <a:is_a_naked:874425907969771469>\n",
            "ropeharry: No, but a little while ago\n",
            "MEE6: <@8496869673740485094> Has advanced to **level 1**! <a:xpeepoJetBubbles:762409048220893234>\n",
            "JDW Economy: \n",
            "safa's demise: c.us_shush\n",
            "safa's demise: ok\n",
            "yung you can be a nice teacher\n",
            "ropeharry: It's just a dumb thing to do\n",
            "mEE6: <@793665757629603894> Has advanced to **level 12**! <a:xpeepoJetBubbles:762409048220893234>\n",
            "kinky fox:  <a:angelpeepo:768416576540794049>\n",
            "ropeharry: This one should do it\n",
            "ropeharry: It was a dumb thing\n",
            "JDW Economy: \n",
            "ropeharry: That was dumb\n",
            "Pulchritudinous Con: It was\n",
            "safa's demise: c.m11\n",
            "JDW Economy: \n",
            "JDW Economy: \n",
            "safa's demise: im going to kill you\n",
            "ropeharry: But if you can talk to me honestly <@!820528307930742418>\n",
            "ropeharry: What is this on\n",
            "JDW Economy: \n",
            "ropeharry: What is it\n",
            "JDW Economy: \n",
            "JDW Economy: \n",
            "ropeharry: I'm here\n",
            "Jungles: <:peepoMikeJayy:7563652023297941632>\n",
            "ropeharry: You are not\n",
            "Cleveland: <:th_sad:553470774092142856> <:th_sad:5534\n",
            "\n",
            "[81 | 423.41] loss=2.07 avg=2.47\n",
            "[82 | 427.57] loss=2.55 avg=2.47\n",
            "[83 | 431.75] loss=2.32 avg=2.47\n",
            "[84 | 435.92] loss=2.10 avg=2.46\n",
            "[85 | 440.09] loss=2.48 avg=2.46\n",
            "[86 | 444.27] loss=2.13 avg=2.45\n",
            "[87 | 448.47] loss=2.36 avg=2.45\n",
            "[88 | 452.65] loss=2.32 avg=2.45\n",
            "[89 | 456.85] loss=2.32 avg=2.45\n",
            "[90 | 461.08] loss=2.51 avg=2.45\n",
            "[91 | 465.34] loss=1.90 avg=2.44\n",
            "[92 | 469.58] loss=1.96 avg=2.43\n",
            "[93 | 473.82] loss=2.21 avg=2.43\n",
            "[94 | 478.00] loss=2.53 avg=2.43\n",
            "[95 | 482.18] loss=2.17 avg=2.43\n",
            "[96 | 486.35] loss=2.43 avg=2.43\n",
            "[97 | 490.53] loss=2.07 avg=2.42\n",
            "[98 | 494.70] loss=2.25 avg=2.42\n",
            "[99 | 498.88] loss=2.11 avg=2.41\n",
            "[100 | 503.06] loss=2.09 avg=2.41\n",
            "Saving checkpoint/run1/model-100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1058: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset='data.txt',\n",
        "              model_name='124M',\n",
        "              steps=100,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=1,\n",
        "              sample_every=20,\n",
        "              save_every=50\n",
        "              )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating Text!\n",
        "\n",
        "Now the final step, we generate text while tuning the parameters as per our requirement!\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text.\n"
      ],
      "metadata": {
        "id": "5gdkbixvedFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y0VByLmQCtIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e470056-0a5b-4dd2-9a4d-49301449b48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, guys!\n",
            "Misc 2 was just released: https://tenor.com/view/ugafa-shoot-gif-191555872\n",
            "okct: just get poggy\n",
            "Jamal: Asshole.\n",
            "Misc 2 was just released: https://tenor.com/view/dog-dog-discord-discord-stream-gif-224986979\n",
            "Classic: Lol\n",
            "Misc 2 was just released: https://tenor.com/view/innovatives-dog-cat-na-super-dog-gif-18499178\n",
            "Classic: Yup\n",
            "Jamal: Oh my.\n",
            "Misc 2 was just released: https://tenor.com/view/dog-dog-discord-discord-discord-gif-224986979\n",
            "okct: <:peepoHappy:75837568980963212>\n",
            "Classic: Hee hee.\n",
            "Classic: Nothing in this world makes me want to run around the planet doing shit like that\n",
            "Jamal: You gotta play or die\n",
            "Classic: nah\n",
            "Jamal: If you can poof, it's 200\n",
            "okct:\n",
            "====================\n",
            "Dani<3: ass im a stupid guy dani<3: we are both too old for this\n",
            "ùÉîùí∂: yoo\n",
            "ùÉîùí∂: y u are\n",
            "ùí∂ùí∂: i cant believe this\n",
            "Sare: c.us literally like half a dozen of the best guys in the game dont know this person\n",
            "Sare: c.us tao/comic\n",
            "ùí∂ùí∂: no\n",
            "ùí∂ùí∂: no\n",
            "JDW Economy: \n",
            "Dani<3: I hope i do this in the future\n",
            "ùí∂ùí∂: just tell me\n",
            "Dani<3: I kinda think it was a one shot\n",
            "ùí∂ùí∂: if i was him\n",
            "ùí∂ùí∂: i could have killed him on a fortnite\n",
            "JDW Economy: \n",
            "ùí∂ùí∂: he is dead\n",
            "JDW Economy: \n",
            "Dani<3: Ohh i told ya\n",
            "ùí∂ùí∂: where is my real IQ\n",
            "JDW Economy: \n",
            "ùí∂ùí∂: ye\n",
            "ùí∂ÔøΩ\n",
            "====================\n",
            "A Mean Joe Sandwich:\n",
            "simp for Shark: Can I buy him a snack?\n",
            "JDW Economy: \n",
            "simp for Shark: <a:xpeepoJetBubbles:762409048220893234>\n",
            "simp for Shark: FIGHT HIMSELF\n",
            "simp for Shark: CAN YOU STAY ON HIS GOOGLE\n",
            "simp for Shark: God\n",
            "simp for Shark: NOTHING\n",
            "simp for Shark: c.us cut\n",
            "simp for Shark: BUT\n",
            "simp for Shark: NO\n",
            "simp for Shark: FOR YEARS\n",
            "simp for Shark: YOU CAN SEE HIM\n",
            "simp for Shark: FOR YEARS\n",
            "simp for Shark: THANKS\n",
            "JDW Economy: \n",
            "Dr.Monty: \n",
            "Amon: Idk\n",
            "JDW Economy: \n",
            "simp for Shark: WHATEVER\n",
            "simp for Shark: MOVE\n",
            "simp for Shark: WOOOOOOOOOOOO\n",
            "simp for Shark: WOOOOOOOOOOO\n",
            "simp for Shark: OOOO\n",
            "simp for Shark: THIS WAS LAZIE\n",
            "JDW Economy: \n",
            "simp\n",
            "====================\n",
            "Controls\n",
            "-Fire: I can't see anything\n",
            "-Fire: Alright\n",
            "(Two-Beat)\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: zorla\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: c.us down\n",
            "kadok: <a:cat3:185805420936159318>\n",
            "SirMonty: <:PING:8187580758572538903>\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: c.us down\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: c.us up\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: c.us down\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: ping\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: c.us down\n",
            "michigan: What\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: kadok\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: kadok\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: <@!9380422480847719905> dont send that\n",
            "„ÅÜ„Å£„Åõ„Åá„Çè: c.m 13\n",
            "kadok: <@!724492875248282532> dont send kadok\n",
            "„ÅÜ\n",
            "====================\n",
            "Wet Seal: <:peepoCringe:75569368491529074>\n",
            "JDW Economy: \n",
            "terroah: what i said\n",
            "adnan.: <a:finit:751534978758918203>\n",
            "cinnamon gal: perms\n",
            "JDW Economy: \n",
            "adnan.: c.us ball\n",
            "JDW Economy: \n",
            "terroah: c.us ball\n",
            "terroah: balls\n",
            "Sl‚±•yer: https://tenor.com/view/astronostar-misc-ball-1-now-gif-15275933\n",
            "JDW Economy: \n",
            "terroah: got it\n",
            "terroah: wtf\n",
            "JDW Economy: \n",
            "adnan.: https://tenor.com/view/astronostar-misc-ball-1-now-gif-15275933\n",
            "DarkFlow: It was what\n",
            "terroah: cool\n",
            "Tiy: <@!663642037573208077> hey\n",
            "JDW Economy: \n",
            "terroah: c.m14\n",
            "terroah: well then why did I come back\n",
            "DarkFlow\n",
            "====================\n"
          ]
        }
      ],
      "source": [
        "gpt2.generate(sess, \n",
        "              length=250,\n",
        "              temperature=0.8,\n",
        "              # prefix=\"\",\n",
        "              nsamples=5,\n",
        "              batch_size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Thoughts\n",
        "\n",
        "\n",
        "This was done as a fun little project. The above method is extremely versatile and can be put into use on a multitude of scenarios thanks to how the wrapper package makes it super easy to implement.\n",
        "\n",
        "##Citations\n",
        "gpt-2-simple - https://github.com/minimaxir/gpt-2-simple\n",
        "\n",
        "Max Woolf's Blog - https://minimaxir.com/"
      ],
      "metadata": {
        "id": "JV1JmaipoRKZ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Train GPT-2 on Discord Chats.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNuBpL2NorpCGI3ualNmqys",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}